---
title: "rahil_things"
output: html_document
date: "2023-05-27"
---

```{r}
library(data.table)
library(rstan)
library(rstanarm)
library(forcats)
library(dplyr)
library(bayesplot)

#Formatting Data to Make easier to Cluster
traindf <- t(Irish_adj_train$indCons)
traindf <- data.frame(ID = rownames(traindf), traindf, row.names = NULL)

testdf <- t(Irish_adj_test$indCons)
testdf <- data.frame(ID = rownames(testdf), testdf, row.names = NULL)

extratrain <- Irish_adj_train$extra
extratest <- Irish_adj_test$extra

# Merge training and testing data frames with the cluster data frame
merged_train <- merge(traindf, hc4, by = "ID")[,-1]
merged_test <- merge(testdf, hc4, by = "ID")[,-1]

# Data Frame with each cluster with summed electricity demand
traindt <- data.table(merged_train)
sumtrain_dt <- traindt[, lapply(.SD, sum), by = cluster]

testdt <- data.table(merged_test)
sumtest_dt <- testdt[, lapply(.SD, sum), by = cluster]
```


```{r}
extratest$dow <- fct_collapse(extratest$dow,
                              Weekend = c('Sun', 'Sat'),
                              Weekday = c('Mon', 'Tue', 'Wed', 'Thu', 'Fri'))

extratrain$dow <- fct_collapse(extratrain$dow,
                              Weekend = c('Sun', 'Sat'),
                              Weekday = c('Mon', 'Tue', 'Wed', 'Thu', 'Fri'))
```


```{r}
# Extract First Time Series
one <- data.table(cbind(t(sumtrain_dt[1,-1]), extratrain$tod))

one <- split(one$V1, as.factor(one$V2))

one <- scale(as.data.table(one), center = TRUE, scale = FALSE)

dum <- model.matrix(~ extratrain$dow - 1)

dum <- dum[(1:nrow(dum)) %% 48 == 1,]
```



```{r}
# Combine the time series with the dummies
X <- cbind(one, dum)
  
Y <- unlist(as.vector(X[,1]))

X <- as.matrix(X[,-1])


stan_code <- "data {
  int<lower=0> N; // number of data items
  int<lower=0> K; // number of predictors
  matrix[N, K] x; // predictor matrix
  vector[N] y; // outcome vector
}
parameters {
  vector[K] beta; // coefficients for predictors
  real<lower=0> tau; // precision parameter
}
transformed parameters {
  real<lower=0> sigma; // standard deviation
  sigma = 1 / sqrt(tau); // Convert precision to standard deviation
}
model {
  tau ~ gamma(2, 0.1); // Gamma prior on the precision
  beta ~ normal(0, 100); // Normal prior on the coefficients
  y ~ normal(x * beta, sigma); // Likelihood
}

generated quantities {
 real y_rep[N];

 for (n in 1:N) {
 y_rep[n] = normal_rng(x[n] * beta, sigma);
 }

}"



# Data for Stan
stan_data <- list(
    N = length(Y),
    K = ncol(X),
    x = X,
    y = Y
  )
  
# Compile and fit the model
fit <- stan(model_code = stan_code, data = stan_data, iter = 2000, chains = 4)
```

```{r}
posterior <- extract(fit)
plot(posterior$beta[,1], type = 'l')
plot(posterior$beta[,49], type = 'l')
```


```{r}
plot(Y)
lines(rowMeans(posterior$y_rep))
```



```{r}
#install.packages("future")
#install.packages("furrr")
library(future)
library(furrr)

# Set up a parallel backend
plan(multisession)


# Define a function to fit one model
fit_model <- function(i) {
  # Extract the relevant time series
  Y <- sumtrain_dt[i,-1]
  
  # Combine the time series with the dummies
  X <- cbind(Y, dum)
  
  # Data for Stan
  stan_data <- list(
    N = length(Y),
    K = ncol(X),
    x = X,
    y = Y
  )
  
  # Compile and fit the model
  fit <- stan(model_code = stan_code, data = stan_data, iter = 2000, chains = 4)
  
  # Return the fit
  return(fit)
}


```

